# 并发

这里介绍 3 种使用 Rust 线程的方法

- 分叉与合并并行
- 通道
- 共享可变状态

Rust 对引用、可变性和生命周期的处理方式在单线程程序中已经足够有价值了，但在并发编程中，这些规则的意义才开始真正显现。它们会扩展你的工具箱，让快速而正确地编写各种风格的多线程代码成为可能。

## 分叉与合并并行

当我们有几个完全独立的任务想要同时完成时，线程最简单的用例就出现了。

假设我们正在对大量文档进行自然语言处理。可以写这样一个循环：

```rust
fn process_files(filenames: Vec<String>) -> io::Result<()> {
    for document in filenames {
        let text = load(&document)?; // TODO：读取源文件
        let results = process(text); // TODO：计算统计信息
        save(&document, results)?; // TODO：写入输出文件
    }
    Ok(())
}

```

下图是上面代码单线程执行的流程示意图

![](./images/1.png)

由于每个文档都是单独处理的，因此要想加快任务处理速度，可以将语料库分成多个块并在单独的线程上处理每个块

![](./images/2.png)

这种模式称为分叉与合并并行。fork（分叉）是启动一个新线程，join（合并）是等待线程完成。

出于以下几个原因，分叉与合并并行很有吸引力

- 非常简单。分叉与合并很容易实现，在 Rust 中更不容易写错。
- 避免了瓶颈。分叉与合并中没有对共享资源的锁定。任何线程只会在最后一步才不得不等待另一个线程。同时，每个线程都可以自由允许。这有助于降低任务切换开销。
- 这种模式在性能方面的数学模型对程序员来说比较直观。在最好的情况下，通过启动 4 个线程，我们只花了 1/4 的时间就能完成原本的工作。上图展示了不应该期望这种理想加速的一个原因：我们可能无法在所有线程之间平均分配工作。另一个原因是，有时分叉与合并程序必须在线程联结后花费一些时间来组合各线程的计算结果，也就是说，完全隔离这些任务可能会产生一些额外的工作。不过，除了这两个原因，任何具有独立工作单元 CPU 密集型程序都可以获得显著的性能提升。
- 很容易推断出程序是否正确。只要线程真正隔离了，分叉与合并程序就是确定性的，这是一个没有竞态条件的并发模型
- 分叉与合并的主要缺点是要求工作单元彼此隔离

### 启动与联结

函数 std::thread::spawn() 会启动一个新线程

```rust
use std::thread;

thread::spawn(|| {
    // 线程代码
});
```

thread::spawn(closure) 会接收一个参数，即一个 FnOnce 闭包或函数型的参数。Rust 会启动一个新线程来运行该闭包或函数的代码。新线程是一个真正的操作系统线程，有自己的栈。

下面是一个更实际的例子，它使用 spawn 实现了之前的 process_files 函数的并行版本

```rust
fn process_files_in_parallel(filenames: Vec<String>) -> io::Result<()> {
    const NTHREADS: usize = 8; // 把工作拆分成几块
    let worklists = split_vec_into_chunks(filenames, NTHREADS); // 将文件切分为多个工作列表

    let mut thread_handles = vec![];

    for worklist in worklists {
        thread_handles.push(spawn(move || process_files(worklist)));
    }
    // 联结：等待所有线程结束
    for handle in thread_handles {
        handle.join().unwrap()?;
    }

    Ok(())
}
```

- 在父线程中，通过 for 循环来定义和填充 worklist。
- 一旦创建了 move 闭包，worklist 就会被移动到此闭包中。
- 然后 spawn 会将闭包（内含 worklist 向量）转移给新的子线程。

这些操作开销很低。String 没有被克隆。事实上，这个过程中并没有发生任何分配和释放。唯一移动的数据是 Vec 本身，只有 3 个机器字。

我们使用之前收集的 JoinHandle 的 .join() 方法来等待所有 8 个线程完成。联结这些线程对于保证程序的正确性是必要的，因为 Rust 程序会在 main 返回后立即退出，即使其他线程仍在运行。这些线程并不会调用析构器，而是直接被“杀死”了。如果这不是你想要的结果，请确保在从 main **_返回之前联结了任何你关心的线程_**。

### 跨线程共享不可变数据

假设我们正在进行的分析需要一个大型的英语单词和短语的数据库

```rust
// 之前
fn process_files(filenames: Vec<String>)
// 之后
fn process_files(filenames: Vec<String>, glossary: &GigabyteMap)
```

这个 glossary 会很大，所以要通过引用传递它。该如何修改, process_files_in_parallel 以便将词汇表传给工作线程呢？

```rust
fn process_files_in_parallel(filenames: Vec<String>, glossary: &GigabyteMap) -> io::Result<()> {
  //...
    for worklist in worklists {
          thread_handles.push(
              spawn(move || process_files(worklist, glossary)) // 错误：不能在闭包中使用引用
          );
    }
  //...
}
```

spawn 会启动独立线程。Rust 无法知道子线程要运行多长时间，因此它假设了最坏的情况：即使在父线程完成并且父线程中的所有值都消失后，子线程仍可能继续运行。显然，如果子线程要持续那么久，那么它运行的闭包也需要持续那么久。但是这个闭包有一个有限的生命周期，它依赖于 glossary 引用，而此引用不需要永久存在。

请注意，Rust 拒绝编译此代码是对的。按照我们编写这个函数的方式，一个线程确实有可能遇到 I/O 错误，导致 process_files_in_parallel 在其他线程完成之前退出。在主线程释放词汇表后，子线程可能仍然会试图使用词汇表。这将是一场竞赛，如果主线程获胜，就会赢得“未定义行为”这份大奖。而 Rust 不允许发生这种事。

spawn 似乎过于开放了，无法支持跨线程共享引用。一种安全的替代方案是为每个线程都克隆整个词汇表，但由于词汇表很大，我们不希望这么做。幸运的是，标准库提供了另一种方式：原子化引用计数。

```RUST
use std::sync::Arc;
fn process_files_in_parallel(filenames: Vec<String>, glossary: Arc<GigabyteMap>) -> io::Result<()> {
    for worklist in worklists {
        // 对.clone()的调用只会克隆Arc并增加引用计数，并不会克隆 GigabyteMap
        let glossary_for_child = glossary.clone();
        thread_handles.push(spawn(move || process_files(worklist, &glossary_for_child)));
    }
}
```
我们更改了 glossary 的类型：要执行并行分析，调用者就必须传入`Arc<GigabyteMap>`，这是指向已使用 `Arc::new(giga_map)` 移入堆中的 `GigabyteMap` 的智能指针。

调用 `glossary.clone()` 时，我们是在复制 `Arc` 智能指针而不是整个 `GigabyteMap`。这相当于增加一次引用计数。

通过此项更改，程序可以编译并运行了，因为它不再依赖于引用的生命周期。只要任何线程拥有 `Arc<GigabyteMap>`，它就会让 GigabyteMap 保持存活状态，即使父线程提前退出也没问题。不会有任何数据竞争，因为 Arc 中的数据是不可变的。