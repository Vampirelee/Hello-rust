# 并发

这里介绍 3 种使用 Rust 线程的方法

- 分叉与合并并行
- 通道
- 共享可变状态

Rust 对引用、可变性和生命周期的处理方式在单线程程序中已经足够有价值了，但在并发编程中，这些规则的意义才开始真正显现。它们会扩展你的工具箱，让快速而正确地编写各种风格的多线程代码成为可能。

## 分叉与合并并行

当我们有几个完全独立的任务想要同时完成时，线程最简单的用例就出现了。

假设我们正在对大量文档进行自然语言处理。可以写这样一个循环：

```rust
fn process_files(filenames: Vec<String>) -> io::Result<()> {
    for document in filenames {
        let text = load(&document)?; // TODO：读取源文件
        let results = process(text); // TODO：计算统计信息
        save(&document, results)?; // TODO：写入输出文件
    }
    Ok(())
}

```

下图是上面代码单线程执行的流程示意图

![](./images/1.png)

由于每个文档都是单独处理的，因此要想加快任务处理速度，可以将语料库分成多个块并在单独的线程上处理每个块

![](./images/2.png)

这种模式称为分叉与合并并行。fork（分叉）是启动一个新线程，join（合并）是等待线程完成。

出于以下几个原因，分叉与合并并行很有吸引力

- 非常简单。分叉与合并很容易实现，在 Rust 中更不容易写错。
- 避免了瓶颈。分叉与合并中没有对共享资源的锁定。任何线程只会在最后一步才不得不等待另一个线程。同时，每个线程都可以自由允许。这有助于降低任务切换开销。
- 这种模式在性能方面的数学模型对程序员来说比较直观。在最好的情况下，通过启动 4 个线程，我们只花了 1/4 的时间就能完成原本的工作。上图展示了不应该期望这种理想加速的一个原因：我们可能无法在所有线程之间平均分配工作。另一个原因是，有时分叉与合并程序必须在线程联结后花费一些时间来组合各线程的计算结果，也就是说，完全隔离这些任务可能会产生一些额外的工作。不过，除了这两个原因，任何具有独立工作单元 CPU 密集型程序都可以获得显著的性能提升。
- 很容易推断出程序是否正确。只要线程真正隔离了，分叉与合并程序就是确定性的，这是一个没有竞态条件的并发模型
- 分叉与合并的主要缺点是要求工作单元彼此隔离

### 启动与联结

函数 std::thread::spawn() 会启动一个新线程

```rust
use std::thread;

thread::spawn(|| {
    // 线程代码
});
```

thread::spawn(closure) 会接收一个参数，即一个 FnOnce 闭包或函数型的参数。Rust 会启动一个新线程来运行该闭包或函数的代码。新线程是一个真正的操作系统线程，有自己的栈。

下面是一个更实际的例子，它使用 spawn 实现了之前的 process_files 函数的并行版本

```rust
fn process_files_in_parallel(filenames: Vec<String>) -> io::Result<()> {
    const NTHREADS: usize = 8; // 把工作拆分成几块
    let worklists = split_vec_into_chunks(filenames, NTHREADS); // 将文件切分为多个工作列表

    let mut thread_handles = vec![];

    for worklist in worklists {
        thread_handles.push(spawn(move || process_files(worklist)));
    }
    // 联结：等待所有线程结束
    for handle in thread_handles {
        handle.join().unwrap()?;
    }

    Ok(())
}
```

- 在父线程中，通过 for 循环来定义和填充 worklist。
- 一旦创建了 move 闭包，worklist 就会被移动到此闭包中。
- 然后 spawn 会将闭包（内含 worklist 向量）转移给新的子线程。

这些操作开销很低。String 没有被克隆。事实上，这个过程中并没有发生任何分配和释放。唯一移动的数据是 Vec 本身，只有 3 个机器字。

我们使用之前收集的 JoinHandle 的 .join() 方法来等待所有 8 个线程完成。联结这些线程对于保证程序的正确性是必要的，因为 Rust 程序会在 main 返回后立即退出，即使其他线程仍在运行。这些线程并不会调用析构器，而是直接被“杀死”了。如果这不是你想要的结果，请确保在从 main **_返回之前联结了任何你关心的线程_**。

### 跨线程共享不可变数据

假设我们正在进行的分析需要一个大型的英语单词和短语的数据库

```rust
// 之前
fn process_files(filenames: Vec<String>)
// 之后
fn process_files(filenames: Vec<String>, glossary: &GigabyteMap)
```

这个 glossary 会很大，所以要通过引用传递它。该如何修改, process_files_in_parallel 以便将词汇表传给工作线程呢？

```rust
fn process_files_in_parallel(filenames: Vec<String>, glossary: &GigabyteMap) -> io::Result<()> {
  //...
    for worklist in worklists {
          thread_handles.push(
              spawn(move || process_files(worklist, glossary)) // 错误：不能在闭包中使用引用
          );
    }
  //...
}
```

spawn 会启动独立线程。Rust 无法知道子线程要运行多长时间，因此它假设了最坏的情况：即使在父线程完成并且父线程中的所有值都消失后，子线程仍可能继续运行。显然，如果子线程要持续那么久，那么它运行的闭包也需要持续那么久。但是这个闭包有一个有限的生命周期，它依赖于 glossary 引用，而此引用不需要永久存在。

请注意，Rust 拒绝编译此代码是对的。按照我们编写这个函数的方式，一个线程确实有可能遇到 I/O 错误，导致 process_files_in_parallel 在其他线程完成之前退出。在主线程释放词汇表后，子线程可能仍然会试图使用词汇表。这将是一场竞赛，如果主线程获胜，就会赢得“未定义行为”这份大奖。而 Rust 不允许发生这种事。

spawn 似乎过于开放了，无法支持跨线程共享引用。一种安全的替代方案是为每个线程都克隆整个词汇表，但由于词汇表很大，我们不希望这么做。幸运的是，标准库提供了另一种方式：原子化引用计数。

```RUST
use std::sync::Arc;
fn process_files_in_parallel(filenames: Vec<String>, glossary: Arc<GigabyteMap>) -> io::Result<()> {
    for worklist in worklists {
        // 对.clone()的调用只会克隆Arc并增加引用计数，并不会克隆 GigabyteMap
        let glossary_for_child = glossary.clone();
        thread_handles.push(spawn(move || process_files(worklist, &glossary_for_child)));
    }
}
```

我们更改了 glossary 的类型：要执行并行分析，调用者就必须传入`Arc<GigabyteMap>`，这是指向已使用 `Arc::new(giga_map)` 移入堆中的 `GigabyteMap` 的智能指针。

调用 `glossary.clone()` 时，我们是在复制 `Arc` 智能指针而不是整个 `GigabyteMap`。这相当于增加一次引用计数。

通过此项更改，程序可以编译并运行了，因为它不再依赖于引用的生命周期。只要任何线程拥有 `Arc<GigabyteMap>`，它就会让 GigabyteMap 保持存活状态，即使父线程提前退出也没问题。不会有任何数据竞争，因为 Arc 中的数据是不可变的。

### rayon

由 Niko Matsakis 和 Josh Stone 设计的 [rayon](https://crates.io/crates/rayon) 库是另一个例子。它提供了两种运行并发任务的方式

```rust
use rayon::prelude::*;

// 并行做两件事
let (v1, v2) = rayon::join(fn1, fn2);

// 并行做 N 件事
giant_vector.par_iter().for_each(|value| {
    do_thing_with_value(value);
})
```

`rayon::join(fn1, fn2)` 只是调用这两个函数并返回两个结果。`.par_iter()` 方法会创建 `ParallelIterator`，这是一个带有 map、filter 和其他方法的值，很像 Rust 的 `Iterator`。在这两种情况下，rayon 都会用自己的工作线程池来尽可能拆分工作。只要告诉 rayon 哪些任务 并行完成就可以了，rayon 会管理这些线程并尽其所能地分派工作。

下图展示了对`giant_vector.par_iter().for_each(...)` 调用的两种思考方式。

- rayon 表现得就好像它为向量中的每个元素启动了一个线程。
- 在幕后，rayon 在每个 CPU 核心上都有一个工作线程，这样效率更高。

这个工作线程池由程序中的所有线程共享。当成千上万个任务同时进来时，rayon 会拆分这些工作。
![](./images/3.png)

下面是一个使用 rayon 的 `process_files_in_parallel` 版本和一个接受`Vec<String>` 型而非 `&str` 型参数的 process_file

```rust
use rayon::prelude::*;
fn process_files_in_parallel(filenames: Vec<String>, glossary: &GigabyteMap) -> io::Result<()>
{
    filenames.par_iter()
        .map(|filename| process_file(filename, glossary))
        .reduce_with(|r1, r2| {
            if r1.is_err() { r1 } else { r2 }
        })
        .unwrap_or(Ok(()))
}
```

比起使用 `std::thread::spawn` 的版本，这段代码更简短，也不需要很多技巧。我们一行一行地看。

- 首先，用 `filenames.par_iter()` 创建一个并行迭代器。
- 然后，用 .map() 在每个文件名上调用 process_file。这会在一系列 `io::Result<()>` 型的值上生成一个 ParallelIterator。
- 最后，用 `.reduce_with()` 来合并结果。在这里，我们会保留第一个错误(如果有的话)并丢弃其余错误。如果想累积所有的错误或者打印它们，也可以在这里修改。
- `reduce_with` 只有在 `filenames` 为空时才会返回一个为 None 的 Option。在这种情况下，我们会用 Option 的 `.unwrap_or()` 方法来生成结果 `Ok(())`。

## 通道

通道是一种单向管道，用于将值从一个线程发送到另一个线程。换句话说，通道是一个线程安全的队列。

下图说明了如何使用通道。通道有点儿像 Unix 管道:一端用于发送数据，另一端用于接收数据。两端通常由两个不同的线程拥有。 但是，Unix 管道用于发送字节，而通道用于发送 Rust 值。 `sender.send(item)` 会将单个值放入通道，`receiver.recv()` 则会移除一个值。值的所有权会从发送线程转移给接收线程。如果通道为空，则 `receiver.recv()` 会一直阻塞到有值发出为止。使用通道，线程可以通过彼此传值来进行通信。这是线程协同工作的一种非常简单的方法，无须使用锁或共享内存。

![](./images/4.png)

这并不是一项新技术。Erlang 中的独立进程和消息传递已经有 30 年 历史了。Unix 管道已经有将近 50 年历史了。我们一般会认为管道具有灵活性和可组合性，而没有意识到它还具有并发的特性，但事实上，管道具有上述所有特性。下图展示了一个 Unix 管道的例子。当然，这 3 个程序也可以同时工作。

![](./images/5.png)

Rust 通道比 Unix 管道更快。发送值只是移动而不是复制，即使要移动的数据结构包含数兆字节数据速度也很快。

### 发送值

在接下来的几节中，我们将使用通道来构建一个创建倒排索引的并发程序，倒排索引是搜索引擎的关键组成部分之一。每个搜索引擎都会处理特定的文档集合。倒排索引是记录“哪些词出现在哪里”的数据库。

我们的程序结构是管道式的，如图所示。管道只是使用通道的众多方法之一，但它们是将并发引入现 有单线程程序的最直观方式。

![](./images/6.png)

这个程序使用总共 5 个线程分别执行了不同的任务。每个线程在程序的生命周期内不断地生成输出。例如，第一个线程只是将源文档从磁盘逐个读取到内存中。该阶段会为每个文档输出一个表示其内容的长 String，因此这个线程与下一个线程可以通过 String 型通道连接。

我们的程序将从启动读取文件的线程开始。假设 documents 是一个 `Vec<PathBuf>`，即一个文件名向量。启动读取文件线程的代码如下所示

```rust
use std::sync::mpsc;
use std::{fs, thread};
let (sender, receiver) = mpsc::channel();

let handle = thread::spawn(move || {
    for filename in documents {
        let text = fs::read_to_string(filename);

        if sender.send(text).is_err() {
            break;
        }
    }
    Ok(())
});
```

通道是 `std::sync::mpsc` 模块的一部分，本章稍后会解释这个名字的含义。下面来看这段代码是如何工作的。先创建一个通道:

```rust
let (sender, receiver) = mpsc::channel();
```

channel 函数会返回一个值对: 发送者和接收者。底层队列的数据结构是标准库的内部实现细节

通道是有类型的。我们要使用这个通道来发送每个文件的文本，因此 `sender` 和 `receiver` 的类型分别为 `Sender<String>` 和 `Receiver<String>`。固然可以写成 `mpsc::channel:: <String>()` 来明确请求一个字符串型通道。但最好还是让 Rust 的类型推断来解决这个问题。

```rust
let handle = thread::spawn(move || {});
```

和以前一样，使用 `std::thread::spawn` 来启动一个线程。 sender(而不是 receiver)的所有权会通过这个 move 闭包转移给新线程。

接下来的几行代码只会从磁盘读取文件

```rust
for filename in documents {
    let text = fs::read_to_string(filename)?;
```

成功读取文件后，要将其文本发送到通道中

```rust
    if sender.send(text).is_err() {
        break;
    }
}
```

`sender.send(text)` 会将 text 值移动到通道中。最终，通道会再次把 text 值转交给接收到该值的任何对象。无论 text 包含 10 行文本还是 10 兆字节，此操作都只会复制 3 个机器字(String 结构体的大小)，相应的 `receiver.recv()` 调用也只会复制 3 个机器字。

`send` 方法和 `recv` 方法都会返回 `Result`，这两种方法只有当通道的另一端已被丢弃时才会失败。如果 `Receiver` 已被丢弃，那么 `send` 调用就会失败，因为如果不失败，则该值会永远存在于通道中:没有 `Receiver`，任何线程都无法再接收它。同样，如果通道中没有值在等待并且 `Sender` 已被丢弃，则 `recv` 调用会失败，因为如果不失败，`recv` 就只能永远等待

没有 Sender，任何线程都无法再发出下一个值。丢弃通道的某一端是正常的“挂断”方式，完成后就会关闭连接。

在我们的代码中，只有当接收者的线程提前退出时，`sender.send(text)` 才会失败。这是使用通道的典型代码。无论接收者是故意退出还是出错退出，读取者线程都可以悄悄地自行关闭。

无论是发生了这种情况还是线程读取完了所有文档，程序都会返回 `Ok(())`

```rust
    Ok(())
});
```

为便于使用，程序会把所有这些代码都包装在一个函数中，该函数会返回至今尚未用到的 `receiver` 和新线程的 `JoinHandle`

```rust
fn start_file_reader_thread(
    documents: Vec<PathBuf>,
) -> (
    mpsc::Receiver<io::Result<String>>,
    thread::JoinHandle<io::Result<()>>,
) {
    let (sender, receiver) = mpsc::channel();
    let handle = thread::spawn(move || {
        for filename in documents {
            let text = fs::read_to_string(filename);

            if sender.send(text).is_err() {
                break;
            }
        }
        Ok(())
    });
    (receiver, handle)
}

```
